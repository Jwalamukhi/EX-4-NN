{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILySmPzyxXww",
        "outputId": "098ea60e-6f5d-400e-fb59-f8a4a4202484"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df.head()\n",
            "     sepal-length  sepal-width  petal-length  petal-width      species\n",
            "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
            "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
            "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
            "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
            "4           5.0          3.6           1.4          0.2  Iris-setosa\n",
            "[1 0 2 1 1 0 1 2 2 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n",
            "confusion_matrix: \n",
            " [[10  0  0]\n",
            " [ 0  8  1]\n",
            " [ 0  0 11]]\n",
            "classification_report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      0.89      0.94         9\n",
            "           2       0.92      1.00      0.96        11\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.96      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Load and name columns\n",
        "url = '/content/IRISDATA.csv'\n",
        "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'species']\n",
        "df = pd.read_csv(url, names=names,header=0)\n",
        "print(\"df.head()\\n \", df.head())\n",
        "# Split features and labels\n",
        "X = df.drop('species', axis=1)\n",
        "y = df['species']\n",
        "# Encode categorical target\n",
        "le = preprocessing.LabelEncoder()\n",
        "yenc = le.fit_transform(y)\n",
        "# Train/test split using encoded labels\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, yenc, test_size=0.20, random_state=42)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train MLP model\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(10,10,10), max_iter=1000)\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "predictions = mlp.predict(X_test)\n",
        "print(predictions)\n",
        "print(\"confusion_matrix: \\n\",confusion_matrix(y_test, predictions))\n",
        "print(\"classification_report: \\n\", classification_report(y_test, predictions))\n",
        "\n"
      ]
    }
  ]
}